{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5a9997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d7797a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sn</th>\n",
       "      <th>compound</th>\n",
       "      <th>ra</th>\n",
       "      <th>rb</th>\n",
       "      <th>xa</th>\n",
       "      <th>xb</th>\n",
       "      <th>za</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>BaCeO3</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.2350</td>\n",
       "      <td>8.7810</td>\n",
       "      <td>6.2120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>BaPrO3</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.2140</td>\n",
       "      <td>8.7220</td>\n",
       "      <td>6.1810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>BaPuO3</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.1930</td>\n",
       "      <td>8.7440</td>\n",
       "      <td>6.2190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>CaCrO3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.66</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.3160</td>\n",
       "      <td>7.4860</td>\n",
       "      <td>5.2870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>CaGeO3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.2688</td>\n",
       "      <td>7.4452</td>\n",
       "      <td>5.2607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sn compound    ra    rb    xa    xb   za       a       b       c\n",
       "0   1   BaCeO3  1.35  0.87  0.89  1.12  2.0  6.2350  8.7810  6.2120\n",
       "1   2   BaPrO3  1.35  0.85  0.89  1.13  2.0  6.2140  8.7220  6.1810\n",
       "2   3   BaPuO3  1.35  0.86  0.89  1.30  2.0  6.1930  8.7440  6.2190\n",
       "3   4   CaCrO3  1.00  0.55  1.00  1.66  2.0  5.3160  7.4860  5.2870\n",
       "4   5   CaGeO3  1.00  0.53  1.00  2.01  2.0  5.2688  7.4452  5.2607"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from cement concrete.csv and look the headers\n",
    "#alat = pd.read_csv('./data/pero.csv',header=0, index_col = 0, usecols= ['ra','rb','xa','xb','za','a','b','c'])\n",
    "alat = pd.read_csv('./data/pero.csv')\n",
    "alat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f10198e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   sn        100 non-null    int64  \n",
      " 1   compound  100 non-null    object \n",
      " 2   ra        100 non-null    float64\n",
      " 3   rb        100 non-null    float64\n",
      " 4   xa        100 non-null    float64\n",
      " 5   xb        100 non-null    float64\n",
      " 6   za        100 non-null    float64\n",
      " 7   a         100 non-null    float64\n",
      " 8   b         100 non-null    float64\n",
      " 9   c         100 non-null    float64\n",
      "dtypes: float64(8), int64(1), object(1)\n",
      "memory usage: 7.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Information of concrete DataFrame\n",
    "alat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b75fbee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the required data columns only for training purpose (features and target)\n",
    "import numpy as np\n",
    "features = np.array(alat[['ra','rb','xa','xb','za']], np.float64)\n",
    "#targets = np.array(alat[['a', 'b', 'c']], np.float64)\n",
    "targets = np.array(alat[['a']], np.float64) # one target at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1929a8d2-3b6b-43ef-8a61-d83403a1367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of data between -1 to 1\n",
    "max_ = features.max(axis=0)\n",
    "min_ = features.min(axis=0)\n",
    "features = (features - min_) / (max_ - min_)\n",
    "targets = (targets - min_) / (max_ - min_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6beada0-1a60-44a2-9aad-f2ba63a22876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation splits\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(features, targets,\n",
    "                                                    random_state=11117,\n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e52099b-ab74-4ff0-8100-2c50f8b1ab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping criteria\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "    patience=300, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffa75069-a6d3-44ce-b9ea-986bba9a77e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Sequential Model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=[5]), # Input layer\n",
    "    layers.Dense(64, activation='relu'), # 1st hidden layer\n",
    "    layers.Dropout(0.2),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(64, activation='relu'), # 2nd hidden layer\n",
    "    layers.Dropout(0.2),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(64, activation='relu'), # 3rd hidden layer\n",
    "    layers.Dropout(0.2),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(64, activation='relu'), # 4th hidden layer\n",
    "    layers.Dropout(0.2),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(64, activation='relu'), # 5th hidden layer\n",
    "    layers.Dropout(0.2),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(64, activation='relu'), # 6th hidden layer\n",
    "    layers.Dropout(0.2),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(64, activation='relu'), # 7th hidden layer\n",
    "    layers.Dropout(0.2),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(64, activation='relu'), # one hidden layer\n",
    "    layers.Dense(1), # output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34746a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mae',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d5a8424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2500\n",
      "2/2 [==============================] - 3s 390ms/step - loss: 5.2983 - val_loss: 5.1902\n",
      "Epoch 2/2500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 5.1279 - val_loss: 5.1775\n",
      "Epoch 3/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 5.0429 - val_loss: 5.1585\n",
      "Epoch 4/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 5.0167 - val_loss: 5.1351\n",
      "Epoch 5/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 4.8608 - val_loss: 5.1085\n",
      "Epoch 6/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 4.8278 - val_loss: 5.0764\n",
      "Epoch 7/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 4.6163 - val_loss: 5.0448\n",
      "Epoch 8/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 4.5119 - val_loss: 5.0120\n",
      "Epoch 9/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 4.4179 - val_loss: 4.9773\n",
      "Epoch 10/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 4.3343 - val_loss: 4.9377\n",
      "Epoch 11/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 4.1687 - val_loss: 4.8955\n",
      "Epoch 12/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 4.1411 - val_loss: 4.8483\n",
      "Epoch 13/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.9600 - val_loss: 4.7944\n",
      "Epoch 14/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.9358 - val_loss: 4.7319\n",
      "Epoch 15/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.8326 - val_loss: 4.6720\n",
      "Epoch 16/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7785 - val_loss: 4.6053\n",
      "Epoch 17/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.6745 - val_loss: 4.5304\n",
      "Epoch 18/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.6037 - val_loss: 4.4526\n",
      "Epoch 19/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.5166 - val_loss: 4.3650\n",
      "Epoch 20/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.4721 - val_loss: 4.2758\n",
      "Epoch 21/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.4297 - val_loss: 4.1796\n",
      "Epoch 22/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.2965 - val_loss: 4.0870\n",
      "Epoch 23/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.2084 - val_loss: 3.9962\n",
      "Epoch 24/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.2421 - val_loss: 3.9062\n",
      "Epoch 25/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.1729 - val_loss: 3.8210\n",
      "Epoch 26/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.1589 - val_loss: 3.7454\n",
      "Epoch 27/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.1110 - val_loss: 3.6768\n",
      "Epoch 28/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.0720 - val_loss: 3.6199\n",
      "Epoch 29/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.0939 - val_loss: 3.5652\n",
      "Epoch 30/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.9966 - val_loss: 3.5183\n",
      "Epoch 31/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.0660 - val_loss: 3.4769\n",
      "Epoch 32/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.0572 - val_loss: 3.4378\n",
      "Epoch 33/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.0122 - val_loss: 3.3997\n",
      "Epoch 34/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.9969 - val_loss: 3.3642\n",
      "Epoch 35/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.0438 - val_loss: 3.3314\n",
      "Epoch 36/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.9655 - val_loss: 3.3030\n",
      "Epoch 37/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.9620 - val_loss: 3.2712\n",
      "Epoch 38/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.9517 - val_loss: 3.2482\n",
      "Epoch 39/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.9476 - val_loss: 3.2228\n",
      "Epoch 40/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.9414 - val_loss: 3.2001\n",
      "Epoch 41/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.9635 - val_loss: 3.1820\n",
      "Epoch 42/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.9516 - val_loss: 3.1682\n",
      "Epoch 43/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.9877 - val_loss: 3.1505\n",
      "Epoch 44/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.9776 - val_loss: 3.1338\n",
      "Epoch 45/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.9458 - val_loss: 3.1228\n",
      "Epoch 46/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.9425 - val_loss: 3.1102\n",
      "Epoch 47/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.9676 - val_loss: 3.1033\n",
      "Epoch 48/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.9464 - val_loss: 3.0945\n",
      "Epoch 49/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.9459 - val_loss: 3.0850\n",
      "Epoch 50/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.9626 - val_loss: 3.0761\n",
      "Epoch 51/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.9614 - val_loss: 3.0700\n",
      "Epoch 52/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.9156 - val_loss: 3.0651\n",
      "Epoch 53/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.9318 - val_loss: 3.0604\n",
      "Epoch 54/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.9380 - val_loss: 3.0536\n",
      "Epoch 55/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.9137 - val_loss: 3.0478\n",
      "Epoch 56/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.9205 - val_loss: 3.0454\n",
      "Epoch 57/2500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 2.9042 - val_loss: 3.0441\n",
      "Epoch 58/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.9179 - val_loss: 3.0475\n",
      "Epoch 59/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.9124 - val_loss: 3.0543\n",
      "Epoch 60/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.9348 - val_loss: 3.0627\n",
      "Epoch 61/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.9120 - val_loss: 3.0692\n",
      "Epoch 62/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8924 - val_loss: 3.0700\n",
      "Epoch 63/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8974 - val_loss: 3.0708\n",
      "Epoch 64/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.9385 - val_loss: 3.0734\n",
      "Epoch 65/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8876 - val_loss: 3.0747\n",
      "Epoch 66/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.9069 - val_loss: 3.0768\n",
      "Epoch 67/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8710 - val_loss: 3.0743\n",
      "Epoch 68/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.9076 - val_loss: 3.0687\n",
      "Epoch 69/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8913 - val_loss: 3.0648\n",
      "Epoch 70/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.9068 - val_loss: 3.0628\n",
      "Epoch 71/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8973 - val_loss: 3.0612\n",
      "Epoch 72/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.9028 - val_loss: 3.0543\n",
      "Epoch 73/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.9106 - val_loss: 3.0464\n",
      "Epoch 74/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.9359 - val_loss: 3.0370\n",
      "Epoch 75/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8668 - val_loss: 3.0276\n",
      "Epoch 76/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.9181 - val_loss: 3.0165\n",
      "Epoch 77/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8976 - val_loss: 3.0111\n",
      "Epoch 78/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8936 - val_loss: 3.0039\n",
      "Epoch 79/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8868 - val_loss: 2.9976\n",
      "Epoch 80/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8978 - val_loss: 2.9963\n",
      "Epoch 81/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.9186 - val_loss: 2.9987\n",
      "Epoch 82/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8999 - val_loss: 2.9938\n",
      "Epoch 83/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8920 - val_loss: 2.9917\n",
      "Epoch 84/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8835 - val_loss: 2.9914\n",
      "Epoch 85/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8889 - val_loss: 2.9914\n",
      "Epoch 86/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.9018 - val_loss: 2.9846\n",
      "Epoch 87/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8619 - val_loss: 2.9818\n",
      "Epoch 88/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8686 - val_loss: 2.9790\n",
      "Epoch 89/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8748 - val_loss: 2.9749\n",
      "Epoch 90/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8908 - val_loss: 2.9674\n",
      "Epoch 91/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8886 - val_loss: 2.9598\n",
      "Epoch 92/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8681 - val_loss: 2.9512\n",
      "Epoch 93/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8779 - val_loss: 2.9366\n",
      "Epoch 94/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8775 - val_loss: 2.9219\n",
      "Epoch 95/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8856 - val_loss: 2.9093\n",
      "Epoch 96/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8800 - val_loss: 2.9026\n",
      "Epoch 97/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8718 - val_loss: 2.8961\n",
      "Epoch 98/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8859 - val_loss: 2.8978\n",
      "Epoch 99/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.9078 - val_loss: 2.9011\n",
      "Epoch 100/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8736 - val_loss: 2.9076\n",
      "Epoch 101/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8711 - val_loss: 2.9180\n",
      "Epoch 102/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8629 - val_loss: 2.9233\n",
      "Epoch 103/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8871 - val_loss: 2.9255\n",
      "Epoch 104/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8473 - val_loss: 2.9282\n",
      "Epoch 105/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8891 - val_loss: 2.9263\n",
      "Epoch 106/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8635 - val_loss: 2.9272\n",
      "Epoch 107/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8558 - val_loss: 2.9318\n",
      "Epoch 108/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8779 - val_loss: 2.9358\n",
      "Epoch 109/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8644 - val_loss: 2.9428\n",
      "Epoch 110/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8825 - val_loss: 2.9552\n",
      "Epoch 111/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8826 - val_loss: 2.9677\n",
      "Epoch 112/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8748 - val_loss: 2.9789\n",
      "Epoch 113/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8918 - val_loss: 2.9896\n",
      "Epoch 114/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8660 - val_loss: 2.9878\n",
      "Epoch 115/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8995 - val_loss: 2.9829\n",
      "Epoch 116/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8576 - val_loss: 2.9793\n",
      "Epoch 117/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8902 - val_loss: 2.9703\n",
      "Epoch 118/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8684 - val_loss: 2.9618\n",
      "Epoch 119/2500\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.8630 - val_loss: 2.9570\n",
      "Epoch 120/2500\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 2.8732 - val_loss: 2.9590\n",
      "Epoch 121/2500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 2.8567 - val_loss: 2.9595\n",
      "Epoch 122/2500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 2.8830 - val_loss: 2.9493\n",
      "Epoch 123/2500\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 2.8678 - val_loss: 2.9378\n",
      "Epoch 124/2500\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 2.8728 - val_loss: 2.9282\n",
      "Epoch 125/2500\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 2.8611 - val_loss: 2.9189\n",
      "Epoch 126/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8391 - val_loss: 2.9209\n",
      "Epoch 127/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8755 - val_loss: 2.9203\n",
      "Epoch 128/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8694 - val_loss: 2.9150\n",
      "Epoch 129/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8725 - val_loss: 2.9085\n",
      "Epoch 130/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8846 - val_loss: 2.9027\n",
      "Epoch 131/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8617 - val_loss: 2.8975\n",
      "Epoch 132/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8767 - val_loss: 2.8951\n",
      "Epoch 133/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8741 - val_loss: 2.8959\n",
      "Epoch 134/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8753 - val_loss: 2.9022\n",
      "Epoch 135/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8627 - val_loss: 2.9108\n",
      "Epoch 136/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8598 - val_loss: 2.9156\n",
      "Epoch 137/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8700 - val_loss: 2.9213\n",
      "Epoch 138/2500\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.8743 - val_loss: 2.9249\n",
      "Epoch 139/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8437 - val_loss: 2.9277\n",
      "Epoch 140/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8697 - val_loss: 2.9282\n",
      "Epoch 141/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8874 - val_loss: 2.9202\n",
      "Epoch 142/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8726 - val_loss: 2.9028\n",
      "Epoch 143/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8868 - val_loss: 2.8820\n",
      "Epoch 144/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8630 - val_loss: 2.8733\n",
      "Epoch 145/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8749 - val_loss: 2.8695\n",
      "Epoch 146/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8376 - val_loss: 2.8687\n",
      "Epoch 147/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8606 - val_loss: 2.8683\n",
      "Epoch 148/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8578 - val_loss: 2.8694\n",
      "Epoch 149/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8802 - val_loss: 2.8702\n",
      "Epoch 150/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8601 - val_loss: 2.8711\n",
      "Epoch 151/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8859 - val_loss: 2.8723\n",
      "Epoch 152/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8592 - val_loss: 2.8690\n",
      "Epoch 153/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8856 - val_loss: 2.8698\n",
      "Epoch 154/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8547 - val_loss: 2.8723\n",
      "Epoch 155/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8663 - val_loss: 2.8713\n",
      "Epoch 156/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8631 - val_loss: 2.8684\n",
      "Epoch 157/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8781 - val_loss: 2.8675\n",
      "Epoch 158/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8530 - val_loss: 2.8702\n",
      "Epoch 159/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8616 - val_loss: 2.8764\n",
      "Epoch 160/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8731 - val_loss: 2.8796\n",
      "Epoch 161/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8461 - val_loss: 2.8847\n",
      "Epoch 162/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8521 - val_loss: 2.8928\n",
      "Epoch 163/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8595 - val_loss: 2.9005\n",
      "Epoch 164/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8648 - val_loss: 2.9099\n",
      "Epoch 165/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8394 - val_loss: 2.9160\n",
      "Epoch 166/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8805 - val_loss: 2.9176\n",
      "Epoch 167/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8699 - val_loss: 2.9100\n",
      "Epoch 168/2500\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.8670 - val_loss: 2.9034\n",
      "Epoch 169/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8721 - val_loss: 2.9026\n",
      "Epoch 170/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8612 - val_loss: 2.9027\n",
      "Epoch 171/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8602 - val_loss: 2.8991\n",
      "Epoch 172/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8568 - val_loss: 2.8910\n",
      "Epoch 173/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8481 - val_loss: 2.8812\n",
      "Epoch 174/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8579 - val_loss: 2.8671\n",
      "Epoch 175/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8595 - val_loss: 2.8590\n",
      "Epoch 176/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8645 - val_loss: 2.8586\n",
      "Epoch 177/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8710 - val_loss: 2.8601\n",
      "Epoch 178/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8617 - val_loss: 2.8636\n",
      "Epoch 179/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8412 - val_loss: 2.8703\n",
      "Epoch 180/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8785 - val_loss: 2.8806\n",
      "Epoch 181/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8600 - val_loss: 2.8924\n",
      "Epoch 182/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8529 - val_loss: 2.9063\n",
      "Epoch 183/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8520 - val_loss: 2.9221\n",
      "Epoch 184/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8565 - val_loss: 2.9376\n",
      "Epoch 185/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8528 - val_loss: 2.9466\n",
      "Epoch 186/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8441 - val_loss: 2.9546\n",
      "Epoch 187/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8427 - val_loss: 2.9509\n",
      "Epoch 188/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8598 - val_loss: 2.9444\n",
      "Epoch 189/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8625 - val_loss: 2.9407\n",
      "Epoch 190/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8443 - val_loss: 2.9457\n",
      "Epoch 191/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8622 - val_loss: 2.9467\n",
      "Epoch 192/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8426 - val_loss: 2.9449\n",
      "Epoch 193/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8502 - val_loss: 2.9426\n",
      "Epoch 194/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8547 - val_loss: 2.9391\n",
      "Epoch 195/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8593 - val_loss: 2.9353\n",
      "Epoch 196/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8617 - val_loss: 2.9250\n",
      "Epoch 197/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8472 - val_loss: 2.9132\n",
      "Epoch 198/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8612 - val_loss: 2.9014\n",
      "Epoch 199/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8765 - val_loss: 2.8932\n",
      "Epoch 200/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8591 - val_loss: 2.8896\n",
      "Epoch 201/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8749 - val_loss: 2.8914\n",
      "Epoch 202/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8387 - val_loss: 2.8926\n",
      "Epoch 203/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8466 - val_loss: 2.8937\n",
      "Epoch 204/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8540 - val_loss: 2.8951\n",
      "Epoch 205/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8670 - val_loss: 2.9010\n",
      "Epoch 206/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8605 - val_loss: 2.9079\n",
      "Epoch 207/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8348 - val_loss: 2.9112\n",
      "Epoch 208/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8476 - val_loss: 2.9097\n",
      "Epoch 209/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8396 - val_loss: 2.9080\n",
      "Epoch 210/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8559 - val_loss: 2.9021\n",
      "Epoch 211/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8366 - val_loss: 2.8968\n",
      "Epoch 212/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8440 - val_loss: 2.8910\n",
      "Epoch 213/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8480 - val_loss: 2.8877\n",
      "Epoch 214/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8480 - val_loss: 2.8836\n",
      "Epoch 215/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8505 - val_loss: 2.8823\n",
      "Epoch 216/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8419 - val_loss: 2.8818\n",
      "Epoch 217/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8462 - val_loss: 2.8845\n",
      "Epoch 218/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8683 - val_loss: 2.8900\n",
      "Epoch 219/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8316 - val_loss: 2.8978\n",
      "Epoch 220/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8565 - val_loss: 2.8996\n",
      "Epoch 221/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8520 - val_loss: 2.8973\n",
      "Epoch 222/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8491 - val_loss: 2.8951\n",
      "Epoch 223/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8340 - val_loss: 2.8900\n",
      "Epoch 224/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8399 - val_loss: 2.8805\n",
      "Epoch 225/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8413 - val_loss: 2.8716\n",
      "Epoch 226/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8381 - val_loss: 2.8619\n",
      "Epoch 227/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8375 - val_loss: 2.8584\n",
      "Epoch 228/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8416 - val_loss: 2.8570\n",
      "Epoch 229/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8474 - val_loss: 2.8554\n",
      "Epoch 230/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8591 - val_loss: 2.8531\n",
      "Epoch 231/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8514 - val_loss: 2.8510\n",
      "Epoch 232/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8458 - val_loss: 2.8507\n",
      "Epoch 233/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8539 - val_loss: 2.8521\n",
      "Epoch 234/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8527 - val_loss: 2.8552\n",
      "Epoch 235/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8521 - val_loss: 2.8587\n",
      "Epoch 236/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8670 - val_loss: 2.8608\n",
      "Epoch 237/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8547 - val_loss: 2.8632\n",
      "Epoch 238/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8422 - val_loss: 2.8675\n",
      "Epoch 239/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8415 - val_loss: 2.8714\n",
      "Epoch 240/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8449 - val_loss: 2.8682\n",
      "Epoch 241/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8369 - val_loss: 2.8644\n",
      "Epoch 242/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8508 - val_loss: 2.8608\n",
      "Epoch 243/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8527 - val_loss: 2.8589\n",
      "Epoch 244/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8553 - val_loss: 2.8566\n",
      "Epoch 245/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8435 - val_loss: 2.8565\n",
      "Epoch 246/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8456 - val_loss: 2.8557\n",
      "Epoch 247/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8407 - val_loss: 2.8545\n",
      "Epoch 248/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8479 - val_loss: 2.8533\n",
      "Epoch 249/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8494 - val_loss: 2.8535\n",
      "Epoch 250/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8605 - val_loss: 2.8540\n",
      "Epoch 251/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8354 - val_loss: 2.8557\n",
      "Epoch 252/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8278 - val_loss: 2.8582\n",
      "Epoch 253/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8377 - val_loss: 2.8605\n",
      "Epoch 254/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8570 - val_loss: 2.8632\n",
      "Epoch 255/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8541 - val_loss: 2.8661\n",
      "Epoch 256/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8460 - val_loss: 2.8769\n",
      "Epoch 257/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8452 - val_loss: 2.8857\n",
      "Epoch 258/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8441 - val_loss: 2.8973\n",
      "Epoch 259/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8375 - val_loss: 2.9058\n",
      "Epoch 260/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8383 - val_loss: 2.9156\n",
      "Epoch 261/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8447 - val_loss: 2.9183\n",
      "Epoch 262/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8504 - val_loss: 2.9090\n",
      "Epoch 263/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8439 - val_loss: 2.8938\n",
      "Epoch 264/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8388 - val_loss: 2.8852\n",
      "Epoch 265/2500\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 2.8413 - val_loss: 2.8779\n",
      "Epoch 266/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8385 - val_loss: 2.8765\n",
      "Epoch 267/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8419 - val_loss: 2.8777\n",
      "Epoch 268/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8436 - val_loss: 2.8820\n",
      "Epoch 269/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8465 - val_loss: 2.8829\n",
      "Epoch 270/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8360 - val_loss: 2.8780\n",
      "Epoch 271/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8349 - val_loss: 2.8747\n",
      "Epoch 272/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8404 - val_loss: 2.8723\n",
      "Epoch 273/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8291 - val_loss: 2.8714\n",
      "Epoch 274/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8432 - val_loss: 2.8702\n",
      "Epoch 275/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8595 - val_loss: 2.8698\n",
      "Epoch 276/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8226 - val_loss: 2.8691\n",
      "Epoch 277/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8360 - val_loss: 2.8685\n",
      "Epoch 278/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8313 - val_loss: 2.8679\n",
      "Epoch 279/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8355 - val_loss: 2.8673\n",
      "Epoch 280/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8233 - val_loss: 2.8671\n",
      "Epoch 281/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8371 - val_loss: 2.8678\n",
      "Epoch 282/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8497 - val_loss: 2.8702\n",
      "Epoch 283/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8319 - val_loss: 2.8714\n",
      "Epoch 284/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8463 - val_loss: 2.8713\n",
      "Epoch 285/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8386 - val_loss: 2.8715\n",
      "Epoch 286/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8540 - val_loss: 2.8720\n",
      "Epoch 287/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8444 - val_loss: 2.8721\n",
      "Epoch 288/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8354 - val_loss: 2.8717\n",
      "Epoch 289/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8417 - val_loss: 2.8703\n",
      "Epoch 290/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8319 - val_loss: 2.8688\n",
      "Epoch 291/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8390 - val_loss: 2.8667\n",
      "Epoch 292/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8292 - val_loss: 2.8642\n",
      "Epoch 293/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8292 - val_loss: 2.8624\n",
      "Epoch 294/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8346 - val_loss: 2.8626\n",
      "Epoch 295/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8259 - val_loss: 2.8651\n",
      "Epoch 296/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8338 - val_loss: 2.8686\n",
      "Epoch 297/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8406 - val_loss: 2.8808\n",
      "Epoch 298/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8310 - val_loss: 2.8943\n",
      "Epoch 299/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8289 - val_loss: 2.8958\n",
      "Epoch 300/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8416 - val_loss: 2.8961\n",
      "Epoch 301/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8425 - val_loss: 2.8965\n",
      "Epoch 302/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8357 - val_loss: 2.8893\n",
      "Epoch 303/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8357 - val_loss: 2.8771\n",
      "Epoch 304/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8297 - val_loss: 2.8655\n",
      "Epoch 305/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8400 - val_loss: 2.8579\n",
      "Epoch 306/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8412 - val_loss: 2.8526\n",
      "Epoch 307/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8369 - val_loss: 2.8494\n",
      "Epoch 308/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8402 - val_loss: 2.8480\n",
      "Epoch 309/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8443 - val_loss: 2.8469\n",
      "Epoch 310/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8366 - val_loss: 2.8469\n",
      "Epoch 311/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8318 - val_loss: 2.8463\n",
      "Epoch 312/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8251 - val_loss: 2.8467\n",
      "Epoch 313/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8299 - val_loss: 2.8479\n",
      "Epoch 314/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8199 - val_loss: 2.8498\n",
      "Epoch 315/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8186 - val_loss: 2.8521\n",
      "Epoch 316/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8387 - val_loss: 2.8530\n",
      "Epoch 317/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8385 - val_loss: 2.8558\n",
      "Epoch 318/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8349 - val_loss: 2.8574\n",
      "Epoch 319/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8316 - val_loss: 2.8568\n",
      "Epoch 320/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8214 - val_loss: 2.8553\n",
      "Epoch 321/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8215 - val_loss: 2.8539\n",
      "Epoch 322/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8335 - val_loss: 2.8528\n",
      "Epoch 323/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8315 - val_loss: 2.8525\n",
      "Epoch 324/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8277 - val_loss: 2.8511\n",
      "Epoch 325/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8433 - val_loss: 2.8499\n",
      "Epoch 326/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8341 - val_loss: 2.8500\n",
      "Epoch 327/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8289 - val_loss: 2.8514\n",
      "Epoch 328/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8305 - val_loss: 2.8524\n",
      "Epoch 329/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8397 - val_loss: 2.8530\n",
      "Epoch 330/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8300 - val_loss: 2.8536\n",
      "Epoch 331/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8293 - val_loss: 2.8537\n",
      "Epoch 332/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8169 - val_loss: 2.8532\n",
      "Epoch 333/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8303 - val_loss: 2.8526\n",
      "Epoch 334/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8256 - val_loss: 2.8529\n",
      "Epoch 335/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8313 - val_loss: 2.8544\n",
      "Epoch 336/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8277 - val_loss: 2.8552\n",
      "Epoch 337/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8191 - val_loss: 2.8543\n",
      "Epoch 338/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8324 - val_loss: 2.8504\n",
      "Epoch 339/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8313 - val_loss: 2.8476\n",
      "Epoch 340/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8332 - val_loss: 2.8470\n",
      "Epoch 341/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8180 - val_loss: 2.8495\n",
      "Epoch 342/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8299 - val_loss: 2.8556\n",
      "Epoch 343/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8306 - val_loss: 2.8577\n",
      "Epoch 344/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8260 - val_loss: 2.8570\n",
      "Epoch 345/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8371 - val_loss: 2.8553\n",
      "Epoch 346/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8502 - val_loss: 2.8537\n",
      "Epoch 347/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8309 - val_loss: 2.8524\n",
      "Epoch 348/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8356 - val_loss: 2.8521\n",
      "Epoch 349/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8271 - val_loss: 2.8515\n",
      "Epoch 350/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8371 - val_loss: 2.8507\n",
      "Epoch 351/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8619 - val_loss: 2.8506\n",
      "Epoch 352/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8383 - val_loss: 2.8522\n",
      "Epoch 353/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8428 - val_loss: 2.8530\n",
      "Epoch 354/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8339 - val_loss: 2.8528\n",
      "Epoch 355/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8257 - val_loss: 2.8536\n",
      "Epoch 356/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8400 - val_loss: 2.8536\n",
      "Epoch 357/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8397 - val_loss: 2.8535\n",
      "Epoch 358/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8279 - val_loss: 2.8541\n",
      "Epoch 359/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8181 - val_loss: 2.8562\n",
      "Epoch 360/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8175 - val_loss: 2.8571\n",
      "Epoch 361/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8248 - val_loss: 2.8568\n",
      "Epoch 362/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8154 - val_loss: 2.8585\n",
      "Epoch 363/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8272 - val_loss: 2.8570\n",
      "Epoch 364/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8164 - val_loss: 2.8532\n",
      "Epoch 365/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8342 - val_loss: 2.8546\n",
      "Epoch 366/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8249 - val_loss: 2.8672\n",
      "Epoch 367/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8321 - val_loss: 2.8824\n",
      "Epoch 368/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8431 - val_loss: 2.8899\n",
      "Epoch 369/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8209 - val_loss: 2.8933\n",
      "Epoch 370/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8448 - val_loss: 2.8838\n",
      "Epoch 371/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8357 - val_loss: 2.8641\n",
      "Epoch 372/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8069 - val_loss: 2.8507\n",
      "Epoch 373/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8192 - val_loss: 2.8443\n",
      "Epoch 374/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8226 - val_loss: 2.8440\n",
      "Epoch 375/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8424 - val_loss: 2.8460\n",
      "Epoch 376/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8350 - val_loss: 2.8456\n",
      "Epoch 377/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8269 - val_loss: 2.8461\n",
      "Epoch 378/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8304 - val_loss: 2.8467\n",
      "Epoch 379/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8279 - val_loss: 2.8508\n",
      "Epoch 380/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8463 - val_loss: 2.8553\n",
      "Epoch 381/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8223 - val_loss: 2.8591\n",
      "Epoch 382/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8220 - val_loss: 2.8594\n",
      "Epoch 383/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8249 - val_loss: 2.8563\n",
      "Epoch 384/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8190 - val_loss: 2.8531\n",
      "Epoch 385/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8337 - val_loss: 2.8494\n",
      "Epoch 386/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8350 - val_loss: 2.8469\n",
      "Epoch 387/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8364 - val_loss: 2.8476\n",
      "Epoch 388/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8252 - val_loss: 2.8484\n",
      "Epoch 389/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8276 - val_loss: 2.8490\n",
      "Epoch 390/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8253 - val_loss: 2.8500\n",
      "Epoch 391/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8166 - val_loss: 2.8514\n",
      "Epoch 392/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8262 - val_loss: 2.8517\n",
      "Epoch 393/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8525 - val_loss: 2.8513\n",
      "Epoch 394/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8146 - val_loss: 2.8522\n",
      "Epoch 395/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8258 - val_loss: 2.8532\n",
      "Epoch 396/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8170 - val_loss: 2.8532\n",
      "Epoch 397/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8271 - val_loss: 2.8521\n",
      "Epoch 398/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8265 - val_loss: 2.8526\n",
      "Epoch 399/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8245 - val_loss: 2.8515\n",
      "Epoch 400/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8247 - val_loss: 2.8514\n",
      "Epoch 401/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8265 - val_loss: 2.8517\n",
      "Epoch 402/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8225 - val_loss: 2.8546\n",
      "Epoch 403/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8170 - val_loss: 2.8630\n",
      "Epoch 404/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8277 - val_loss: 2.8766\n",
      "Epoch 405/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8270 - val_loss: 2.8855\n",
      "Epoch 406/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8425 - val_loss: 2.8864\n",
      "Epoch 407/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8197 - val_loss: 2.8856\n",
      "Epoch 408/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8304 - val_loss: 2.8833\n",
      "Epoch 409/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8314 - val_loss: 2.8807\n",
      "Epoch 410/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8386 - val_loss: 2.8750\n",
      "Epoch 411/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8313 - val_loss: 2.8722\n",
      "Epoch 412/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8311 - val_loss: 2.8649\n",
      "Epoch 413/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8231 - val_loss: 2.8567\n",
      "Epoch 414/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8253 - val_loss: 2.8513\n",
      "Epoch 415/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8364 - val_loss: 2.8440\n",
      "Epoch 416/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8279 - val_loss: 2.8396\n",
      "Epoch 417/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8182 - val_loss: 2.8381\n",
      "Epoch 418/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8244 - val_loss: 2.8388\n",
      "Epoch 419/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8292 - val_loss: 2.8398\n",
      "Epoch 420/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8228 - val_loss: 2.8405\n",
      "Epoch 421/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8246 - val_loss: 2.8393\n",
      "Epoch 422/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8135 - val_loss: 2.8387\n",
      "Epoch 423/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8171 - val_loss: 2.8371\n",
      "Epoch 424/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8208 - val_loss: 2.8393\n",
      "Epoch 425/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8086 - val_loss: 2.8412\n",
      "Epoch 426/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8270 - val_loss: 2.8409\n",
      "Epoch 427/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8221 - val_loss: 2.8402\n",
      "Epoch 428/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8259 - val_loss: 2.8405\n",
      "Epoch 429/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8203 - val_loss: 2.8395\n",
      "Epoch 430/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8314 - val_loss: 2.8395\n",
      "Epoch 431/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8146 - val_loss: 2.8395\n",
      "Epoch 432/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8082 - val_loss: 2.8396\n",
      "Epoch 433/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8144 - val_loss: 2.8405\n",
      "Epoch 434/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8251 - val_loss: 2.8397\n",
      "Epoch 435/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8178 - val_loss: 2.8393\n",
      "Epoch 436/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8094 - val_loss: 2.8403\n",
      "Epoch 437/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8242 - val_loss: 2.8434\n",
      "Epoch 438/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8248 - val_loss: 2.8451\n",
      "Epoch 439/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8154 - val_loss: 2.8454\n",
      "Epoch 440/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8153 - val_loss: 2.8448\n",
      "Epoch 441/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8111 - val_loss: 2.8458\n",
      "Epoch 442/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8139 - val_loss: 2.8424\n",
      "Epoch 443/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8281 - val_loss: 2.8380\n",
      "Epoch 444/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8217 - val_loss: 2.8356\n",
      "Epoch 445/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8225 - val_loss: 2.8356\n",
      "Epoch 446/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8228 - val_loss: 2.8362\n",
      "Epoch 447/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8355 - val_loss: 2.8367\n",
      "Epoch 448/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8189 - val_loss: 2.8384\n",
      "Epoch 449/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8146 - val_loss: 2.8393\n",
      "Epoch 450/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8191 - val_loss: 2.8375\n",
      "Epoch 451/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8165 - val_loss: 2.8365\n",
      "Epoch 452/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8124 - val_loss: 2.8359\n",
      "Epoch 453/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8150 - val_loss: 2.8357\n",
      "Epoch 454/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8272 - val_loss: 2.8360\n",
      "Epoch 455/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8308 - val_loss: 2.8362\n",
      "Epoch 456/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8070 - val_loss: 2.8373\n",
      "Epoch 457/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8188 - val_loss: 2.8383\n",
      "Epoch 458/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8192 - val_loss: 2.8394\n",
      "Epoch 459/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8151 - val_loss: 2.8431\n",
      "Epoch 460/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8177 - val_loss: 2.8507\n",
      "Epoch 461/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8082 - val_loss: 2.8612\n",
      "Epoch 462/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8239 - val_loss: 2.8651\n",
      "Epoch 463/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8112 - val_loss: 2.8640\n",
      "Epoch 464/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8227 - val_loss: 2.8561\n",
      "Epoch 465/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8084 - val_loss: 2.8507\n",
      "Epoch 466/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8146 - val_loss: 2.8461\n",
      "Epoch 467/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8088 - val_loss: 2.8438\n",
      "Epoch 468/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8154 - val_loss: 2.8440\n",
      "Epoch 469/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8220 - val_loss: 2.8451\n",
      "Epoch 470/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8177 - val_loss: 2.8433\n",
      "Epoch 471/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8170 - val_loss: 2.8410\n",
      "Epoch 472/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8130 - val_loss: 2.8387\n",
      "Epoch 473/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8139 - val_loss: 2.8372\n",
      "Epoch 474/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8095 - val_loss: 2.8392\n",
      "Epoch 475/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8251 - val_loss: 2.8437\n",
      "Epoch 476/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8144 - val_loss: 2.8501\n",
      "Epoch 477/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8200 - val_loss: 2.8561\n",
      "Epoch 478/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8179 - val_loss: 2.8591\n",
      "Epoch 479/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8118 - val_loss: 2.8590\n",
      "Epoch 480/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8214 - val_loss: 2.8574\n",
      "Epoch 481/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8242 - val_loss: 2.8610\n",
      "Epoch 482/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8139 - val_loss: 2.8661\n",
      "Epoch 483/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8148 - val_loss: 2.8724\n",
      "Epoch 484/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8202 - val_loss: 2.8779\n",
      "Epoch 485/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8195 - val_loss: 2.8749\n",
      "Epoch 486/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8092 - val_loss: 2.8672\n",
      "Epoch 487/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8135 - val_loss: 2.8606\n",
      "Epoch 488/2500\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 2.8139 - val_loss: 2.8484\n",
      "Epoch 489/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8193 - val_loss: 2.8379\n",
      "Epoch 490/2500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 2.8095 - val_loss: 2.8327\n",
      "Epoch 491/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8087 - val_loss: 2.8320\n",
      "Epoch 492/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8186 - val_loss: 2.8322\n",
      "Epoch 493/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8190 - val_loss: 2.8354\n",
      "Epoch 494/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8145 - val_loss: 2.8421\n",
      "Epoch 495/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8290 - val_loss: 2.8459\n",
      "Epoch 496/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8079 - val_loss: 2.8482\n",
      "Epoch 497/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8077 - val_loss: 2.8556\n",
      "Epoch 498/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8227 - val_loss: 2.8576\n",
      "Epoch 499/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8086 - val_loss: 2.8653\n",
      "Epoch 500/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8166 - val_loss: 2.8741\n",
      "Epoch 501/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8169 - val_loss: 2.8805\n",
      "Epoch 502/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8163 - val_loss: 2.8847\n",
      "Epoch 503/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8216 - val_loss: 2.8783\n",
      "Epoch 504/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8174 - val_loss: 2.8666\n",
      "Epoch 505/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8146 - val_loss: 2.8565\n",
      "Epoch 506/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8069 - val_loss: 2.8489\n",
      "Epoch 507/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8228 - val_loss: 2.8425\n",
      "Epoch 508/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8141 - val_loss: 2.8393\n",
      "Epoch 509/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8136 - val_loss: 2.8388\n",
      "Epoch 510/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8153 - val_loss: 2.8414\n",
      "Epoch 511/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8139 - val_loss: 2.8424\n",
      "Epoch 512/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8136 - val_loss: 2.8426\n",
      "Epoch 513/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8166 - val_loss: 2.8434\n",
      "Epoch 514/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8187 - val_loss: 2.8428\n",
      "Epoch 515/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8128 - val_loss: 2.8392\n",
      "Epoch 516/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8173 - val_loss: 2.8406\n",
      "Epoch 517/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8181 - val_loss: 2.8475\n",
      "Epoch 518/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8318 - val_loss: 2.8470\n",
      "Epoch 519/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8115 - val_loss: 2.8464\n",
      "Epoch 520/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8102 - val_loss: 2.8456\n",
      "Epoch 521/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8188 - val_loss: 2.8454\n",
      "Epoch 522/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8274 - val_loss: 2.8443\n",
      "Epoch 523/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8107 - val_loss: 2.8388\n",
      "Epoch 524/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8101 - val_loss: 2.8329\n",
      "Epoch 525/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8191 - val_loss: 2.8322\n",
      "Epoch 526/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8216 - val_loss: 2.8400\n",
      "Epoch 527/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8233 - val_loss: 2.8473\n",
      "Epoch 528/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8199 - val_loss: 2.8456\n",
      "Epoch 529/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8366 - val_loss: 2.8337\n",
      "Epoch 530/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8106 - val_loss: 2.8268\n",
      "Epoch 531/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8207 - val_loss: 2.8259\n",
      "Epoch 532/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7986 - val_loss: 2.8260\n",
      "Epoch 533/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8153 - val_loss: 2.8257\n",
      "Epoch 534/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8035 - val_loss: 2.8261\n",
      "Epoch 535/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8148 - val_loss: 2.8269\n",
      "Epoch 536/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8159 - val_loss: 2.8260\n",
      "Epoch 537/2500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8130 - val_loss: 2.8240\n",
      "Epoch 538/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8188 - val_loss: 2.8244\n",
      "Epoch 539/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8141 - val_loss: 2.8243\n",
      "Epoch 540/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8067 - val_loss: 2.8259\n",
      "Epoch 541/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8116 - val_loss: 2.8267\n",
      "Epoch 542/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8133 - val_loss: 2.8281\n",
      "Epoch 543/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8200 - val_loss: 2.8315\n",
      "Epoch 544/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8106 - val_loss: 2.8346\n",
      "Epoch 545/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8024 - val_loss: 2.8362\n",
      "Epoch 546/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8139 - val_loss: 2.8362\n",
      "Epoch 547/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8097 - val_loss: 2.8395\n",
      "Epoch 548/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8052 - val_loss: 2.8467\n",
      "Epoch 549/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8201 - val_loss: 2.8508\n",
      "Epoch 550/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8113 - val_loss: 2.8518\n",
      "Epoch 551/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8083 - val_loss: 2.8577\n",
      "Epoch 552/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8081 - val_loss: 2.8545\n",
      "Epoch 553/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8113 - val_loss: 2.8519\n",
      "Epoch 554/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8111 - val_loss: 2.8479\n",
      "Epoch 555/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8186 - val_loss: 2.8428\n",
      "Epoch 556/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8166 - val_loss: 2.8362\n",
      "Epoch 557/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8137 - val_loss: 2.8314\n",
      "Epoch 558/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8067 - val_loss: 2.8294\n",
      "Epoch 559/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8185 - val_loss: 2.8304\n",
      "Epoch 560/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8109 - val_loss: 2.8331\n",
      "Epoch 561/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8113 - val_loss: 2.8358\n",
      "Epoch 562/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7976 - val_loss: 2.8421\n",
      "Epoch 563/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8175 - val_loss: 2.8491\n",
      "Epoch 564/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8153 - val_loss: 2.8556\n",
      "Epoch 565/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7935 - val_loss: 2.8653\n",
      "Epoch 566/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8055 - val_loss: 2.8760\n",
      "Epoch 567/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8230 - val_loss: 2.8765\n",
      "Epoch 568/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8221 - val_loss: 2.8703\n",
      "Epoch 569/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8108 - val_loss: 2.8682\n",
      "Epoch 570/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8128 - val_loss: 2.8719\n",
      "Epoch 571/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8095 - val_loss: 2.8754\n",
      "Epoch 572/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8058 - val_loss: 2.8773\n",
      "Epoch 573/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8092 - val_loss: 2.8723\n",
      "Epoch 574/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8047 - val_loss: 2.8704\n",
      "Epoch 575/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8180 - val_loss: 2.8626\n",
      "Epoch 576/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8008 - val_loss: 2.8564\n",
      "Epoch 577/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8059 - val_loss: 2.8532\n",
      "Epoch 578/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8106 - val_loss: 2.8506\n",
      "Epoch 579/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8077 - val_loss: 2.8504\n",
      "Epoch 580/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8051 - val_loss: 2.8526\n",
      "Epoch 581/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8092 - val_loss: 2.8515\n",
      "Epoch 582/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8102 - val_loss: 2.8465\n",
      "Epoch 583/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8202 - val_loss: 2.8393\n",
      "Epoch 584/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8158 - val_loss: 2.8345\n",
      "Epoch 585/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8132 - val_loss: 2.8363\n",
      "Epoch 586/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8126 - val_loss: 2.8420\n",
      "Epoch 587/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8067 - val_loss: 2.8524\n",
      "Epoch 588/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7995 - val_loss: 2.8674\n",
      "Epoch 589/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8174 - val_loss: 2.8846\n",
      "Epoch 590/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8112 - val_loss: 2.9000\n",
      "Epoch 591/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8249 - val_loss: 2.9066\n",
      "Epoch 592/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8119 - val_loss: 2.9136\n",
      "Epoch 593/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8179 - val_loss: 2.9123\n",
      "Epoch 594/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8146 - val_loss: 2.9047\n",
      "Epoch 595/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8081 - val_loss: 2.8987\n",
      "Epoch 596/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8083 - val_loss: 2.8917\n",
      "Epoch 597/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8023 - val_loss: 2.8854\n",
      "Epoch 598/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8062 - val_loss: 2.8758\n",
      "Epoch 599/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8180 - val_loss: 2.8649\n",
      "Epoch 600/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8076 - val_loss: 2.8567\n",
      "Epoch 601/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8047 - val_loss: 2.8488\n",
      "Epoch 602/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8056 - val_loss: 2.8448\n",
      "Epoch 603/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7992 - val_loss: 2.8419\n",
      "Epoch 604/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8126 - val_loss: 2.8443\n",
      "Epoch 605/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8040 - val_loss: 2.8486\n",
      "Epoch 606/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8078 - val_loss: 2.8526\n",
      "Epoch 607/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8101 - val_loss: 2.8589\n",
      "Epoch 608/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8093 - val_loss: 2.8600\n",
      "Epoch 609/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7983 - val_loss: 2.8665\n",
      "Epoch 610/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8131 - val_loss: 2.8748\n",
      "Epoch 611/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8003 - val_loss: 2.8827\n",
      "Epoch 612/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8118 - val_loss: 2.8857\n",
      "Epoch 613/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8021 - val_loss: 2.8960\n",
      "Epoch 614/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8109 - val_loss: 2.9073\n",
      "Epoch 615/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8095 - val_loss: 2.9132\n",
      "Epoch 616/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8042 - val_loss: 2.9107\n",
      "Epoch 617/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8037 - val_loss: 2.9042\n",
      "Epoch 618/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7993 - val_loss: 2.8961\n",
      "Epoch 619/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8062 - val_loss: 2.8919\n",
      "Epoch 620/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8010 - val_loss: 2.8891\n",
      "Epoch 621/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8062 - val_loss: 2.8885\n",
      "Epoch 622/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7972 - val_loss: 2.8887\n",
      "Epoch 623/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8094 - val_loss: 2.8838\n",
      "Epoch 624/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7948 - val_loss: 2.8830\n",
      "Epoch 625/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7922 - val_loss: 2.8829\n",
      "Epoch 626/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7955 - val_loss: 2.8805\n",
      "Epoch 627/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8067 - val_loss: 2.8756\n",
      "Epoch 628/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8224 - val_loss: 2.8634\n",
      "Epoch 629/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8153 - val_loss: 2.8534\n",
      "Epoch 630/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8181 - val_loss: 2.8496\n",
      "Epoch 631/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8119 - val_loss: 2.8503\n",
      "Epoch 632/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8004 - val_loss: 2.8553\n",
      "Epoch 633/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8061 - val_loss: 2.8672\n",
      "Epoch 634/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8181 - val_loss: 2.8777\n",
      "Epoch 635/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8027 - val_loss: 2.8810\n",
      "Epoch 636/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8040 - val_loss: 2.8863\n",
      "Epoch 637/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8139 - val_loss: 2.8906\n",
      "Epoch 638/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8077 - val_loss: 2.8951\n",
      "Epoch 639/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7963 - val_loss: 2.8923\n",
      "Epoch 640/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8006 - val_loss: 2.8800\n",
      "Epoch 641/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8060 - val_loss: 2.8642\n",
      "Epoch 642/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8042 - val_loss: 2.8564\n",
      "Epoch 643/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8084 - val_loss: 2.8538\n",
      "Epoch 644/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8008 - val_loss: 2.8548\n",
      "Epoch 645/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8083 - val_loss: 2.8606\n",
      "Epoch 646/2500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 2.8124 - val_loss: 2.8656\n",
      "Epoch 647/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8023 - val_loss: 2.8683\n",
      "Epoch 648/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8073 - val_loss: 2.8696\n",
      "Epoch 649/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8027 - val_loss: 2.8713\n",
      "Epoch 650/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.7995 - val_loss: 2.8784\n",
      "Epoch 651/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8061 - val_loss: 2.8848\n",
      "Epoch 652/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8050 - val_loss: 2.8855\n",
      "Epoch 653/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8076 - val_loss: 2.8747\n",
      "Epoch 654/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8024 - val_loss: 2.8685\n",
      "Epoch 655/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8124 - val_loss: 2.8543\n",
      "Epoch 656/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.7962 - val_loss: 2.8479\n",
      "Epoch 657/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8051 - val_loss: 2.8461\n",
      "Epoch 658/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8021 - val_loss: 2.8460\n",
      "Epoch 659/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8052 - val_loss: 2.8438\n",
      "Epoch 660/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8041 - val_loss: 2.8437\n",
      "Epoch 661/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8083 - val_loss: 2.8465\n",
      "Epoch 662/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8042 - val_loss: 2.8488\n",
      "Epoch 663/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8013 - val_loss: 2.8519\n",
      "Epoch 664/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8059 - val_loss: 2.8550\n",
      "Epoch 665/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.7987 - val_loss: 2.8640\n",
      "Epoch 666/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8006 - val_loss: 2.8710\n",
      "Epoch 667/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8091 - val_loss: 2.8758\n",
      "Epoch 668/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.7998 - val_loss: 2.8762\n",
      "Epoch 669/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8027 - val_loss: 2.8798\n",
      "Epoch 670/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8029 - val_loss: 2.8837\n",
      "Epoch 671/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8093 - val_loss: 2.8837\n",
      "Epoch 672/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.7996 - val_loss: 2.8804\n",
      "Epoch 673/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8002 - val_loss: 2.8768\n",
      "Epoch 674/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.7995 - val_loss: 2.8743\n",
      "Epoch 675/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8088 - val_loss: 2.8728\n",
      "Epoch 676/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.7958 - val_loss: 2.8726\n",
      "Epoch 677/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8117 - val_loss: 2.8733\n",
      "Epoch 678/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8002 - val_loss: 2.8734\n",
      "Epoch 679/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.7973 - val_loss: 2.8699\n",
      "Epoch 680/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8050 - val_loss: 2.8658\n",
      "Epoch 681/2500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.8088 - val_loss: 2.8617\n",
      "Epoch 682/2500\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 2.8040 - val_loss: 2.8575\n",
      "Epoch 683/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8098 - val_loss: 2.8542\n",
      "Epoch 684/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7996 - val_loss: 2.8518\n",
      "Epoch 685/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8070 - val_loss: 2.8513\n",
      "Epoch 686/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8084 - val_loss: 2.8562\n",
      "Epoch 687/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8036 - val_loss: 2.8637\n",
      "Epoch 688/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8064 - val_loss: 2.8736\n",
      "Epoch 689/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7973 - val_loss: 2.8853\n",
      "Epoch 690/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8110 - val_loss: 2.8877\n",
      "Epoch 691/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8147 - val_loss: 2.8801\n",
      "Epoch 692/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8095 - val_loss: 2.8740\n",
      "Epoch 693/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8195 - val_loss: 2.8687\n",
      "Epoch 694/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7966 - val_loss: 2.8662\n",
      "Epoch 695/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7975 - val_loss: 2.8629\n",
      "Epoch 696/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8012 - val_loss: 2.8610\n",
      "Epoch 697/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8053 - val_loss: 2.8599\n",
      "Epoch 698/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7978 - val_loss: 2.8600\n",
      "Epoch 699/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.7979 - val_loss: 2.8608\n",
      "Epoch 700/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8012 - val_loss: 2.8599\n",
      "Epoch 701/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8114 - val_loss: 2.8572\n",
      "Epoch 702/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8070 - val_loss: 2.8518\n",
      "Epoch 703/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7985 - val_loss: 2.8472\n",
      "Epoch 704/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7994 - val_loss: 2.8453\n",
      "Epoch 705/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8040 - val_loss: 2.8492\n",
      "Epoch 706/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8020 - val_loss: 2.8547\n",
      "Epoch 707/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8021 - val_loss: 2.8607\n",
      "Epoch 708/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8008 - val_loss: 2.8602\n",
      "Epoch 709/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7997 - val_loss: 2.8569\n",
      "Epoch 710/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8081 - val_loss: 2.8534\n",
      "Epoch 711/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7961 - val_loss: 2.8516\n",
      "Epoch 712/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8054 - val_loss: 2.8522\n",
      "Epoch 713/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8167 - val_loss: 2.8515\n",
      "Epoch 714/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7966 - val_loss: 2.8505\n",
      "Epoch 715/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8079 - val_loss: 2.8525\n",
      "Epoch 716/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7997 - val_loss: 2.8538\n",
      "Epoch 717/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8058 - val_loss: 2.8537\n",
      "Epoch 718/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8000 - val_loss: 2.8555\n",
      "Epoch 719/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8076 - val_loss: 2.8625\n",
      "Epoch 720/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8043 - val_loss: 2.8719\n",
      "Epoch 721/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8026 - val_loss: 2.8735\n",
      "Epoch 722/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8018 - val_loss: 2.8704\n",
      "Epoch 723/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7992 - val_loss: 2.8658\n",
      "Epoch 724/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8020 - val_loss: 2.8686\n",
      "Epoch 725/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7975 - val_loss: 2.8784\n",
      "Epoch 726/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8108 - val_loss: 2.8783\n",
      "Epoch 727/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8037 - val_loss: 2.8749\n",
      "Epoch 728/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8109 - val_loss: 2.8660\n",
      "Epoch 729/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8074 - val_loss: 2.8607\n",
      "Epoch 730/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7953 - val_loss: 2.8573\n",
      "Epoch 731/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7974 - val_loss: 2.8538\n",
      "Epoch 732/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7963 - val_loss: 2.8505\n",
      "Epoch 733/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8051 - val_loss: 2.8460\n",
      "Epoch 734/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8004 - val_loss: 2.8441\n",
      "Epoch 735/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8050 - val_loss: 2.8443\n",
      "Epoch 736/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8002 - val_loss: 2.8440\n",
      "Epoch 737/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7991 - val_loss: 2.8450\n",
      "Epoch 738/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7992 - val_loss: 2.8514\n",
      "Epoch 739/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8036 - val_loss: 2.8609\n",
      "Epoch 740/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7933 - val_loss: 2.8786\n",
      "Epoch 741/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7955 - val_loss: 2.8976\n",
      "Epoch 742/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7944 - val_loss: 2.9171\n",
      "Epoch 743/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8004 - val_loss: 2.9195\n",
      "Epoch 744/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7982 - val_loss: 2.9098\n",
      "Epoch 745/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8130 - val_loss: 2.8930\n",
      "Epoch 746/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8157 - val_loss: 2.8709\n",
      "Epoch 747/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8059 - val_loss: 2.8603\n",
      "Epoch 748/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8087 - val_loss: 2.8578\n",
      "Epoch 749/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8059 - val_loss: 2.8558\n",
      "Epoch 750/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7969 - val_loss: 2.8570\n",
      "Epoch 751/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8048 - val_loss: 2.8594\n",
      "Epoch 752/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8040 - val_loss: 2.8599\n",
      "Epoch 753/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7935 - val_loss: 2.8619\n",
      "Epoch 754/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7969 - val_loss: 2.8651\n",
      "Epoch 755/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7975 - val_loss: 2.8739\n",
      "Epoch 756/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8050 - val_loss: 2.8840\n",
      "Epoch 757/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8015 - val_loss: 2.8951\n",
      "Epoch 758/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8153 - val_loss: 2.8988\n",
      "Epoch 759/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8133 - val_loss: 2.8908\n",
      "Epoch 760/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8077 - val_loss: 2.8703\n",
      "Epoch 761/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.7991 - val_loss: 2.8565\n",
      "Epoch 762/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8048 - val_loss: 2.8497\n",
      "Epoch 763/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7998 - val_loss: 2.8491\n",
      "Epoch 764/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7958 - val_loss: 2.8497\n",
      "Epoch 765/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8005 - val_loss: 2.8524\n",
      "Epoch 766/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8003 - val_loss: 2.8519\n",
      "Epoch 767/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7948 - val_loss: 2.8513\n",
      "Epoch 768/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8005 - val_loss: 2.8527\n",
      "Epoch 769/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7987 - val_loss: 2.8545\n",
      "Epoch 770/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8002 - val_loss: 2.8537\n",
      "Epoch 771/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8069 - val_loss: 2.8464\n",
      "Epoch 772/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8073 - val_loss: 2.8412\n",
      "Epoch 773/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8042 - val_loss: 2.8428\n",
      "Epoch 774/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8011 - val_loss: 2.8442\n",
      "Epoch 775/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8016 - val_loss: 2.8430\n",
      "Epoch 776/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7986 - val_loss: 2.8397\n",
      "Epoch 777/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8008 - val_loss: 2.8388\n",
      "Epoch 778/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7935 - val_loss: 2.8376\n",
      "Epoch 779/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7948 - val_loss: 2.8387\n",
      "Epoch 780/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8031 - val_loss: 2.8447\n",
      "Epoch 781/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7950 - val_loss: 2.8523\n",
      "Epoch 782/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7953 - val_loss: 2.8545\n",
      "Epoch 783/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8116 - val_loss: 2.8567\n",
      "Epoch 784/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8015 - val_loss: 2.8566\n",
      "Epoch 785/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7986 - val_loss: 2.8517\n",
      "Epoch 786/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7996 - val_loss: 2.8445\n",
      "Epoch 787/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8039 - val_loss: 2.8419\n",
      "Epoch 788/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7972 - val_loss: 2.8441\n",
      "Epoch 789/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7904 - val_loss: 2.8478\n",
      "Epoch 790/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7996 - val_loss: 2.8492\n",
      "Epoch 791/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7986 - val_loss: 2.8503\n",
      "Epoch 792/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7955 - val_loss: 2.8493\n",
      "Epoch 793/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8007 - val_loss: 2.8445\n",
      "Epoch 794/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8053 - val_loss: 2.8377\n",
      "Epoch 795/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8026 - val_loss: 2.8334\n",
      "Epoch 796/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7996 - val_loss: 2.8328\n",
      "Epoch 797/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8006 - val_loss: 2.8376\n",
      "Epoch 798/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7987 - val_loss: 2.8426\n",
      "Epoch 799/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7938 - val_loss: 2.8496\n",
      "Epoch 800/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7993 - val_loss: 2.8552\n",
      "Epoch 801/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8053 - val_loss: 2.8543\n",
      "Epoch 802/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7986 - val_loss: 2.8590\n",
      "Epoch 803/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8053 - val_loss: 2.8574\n",
      "Epoch 804/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8029 - val_loss: 2.8534\n",
      "Epoch 805/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7960 - val_loss: 2.8533\n",
      "Epoch 806/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8030 - val_loss: 2.8531\n",
      "Epoch 807/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8011 - val_loss: 2.8513\n",
      "Epoch 808/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7985 - val_loss: 2.8476\n",
      "Epoch 809/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7870 - val_loss: 2.8461\n",
      "Epoch 810/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7950 - val_loss: 2.8485\n",
      "Epoch 811/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7924 - val_loss: 2.8527\n",
      "Epoch 812/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8034 - val_loss: 2.8572\n",
      "Epoch 813/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7965 - val_loss: 2.8616\n",
      "Epoch 814/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.7941 - val_loss: 2.8634\n",
      "Epoch 815/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8036 - val_loss: 2.8654\n",
      "Epoch 816/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7973 - val_loss: 2.8645\n",
      "Epoch 817/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7912 - val_loss: 2.8658\n",
      "Epoch 818/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8019 - val_loss: 2.8673\n",
      "Epoch 819/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7998 - val_loss: 2.8645\n",
      "Epoch 820/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7986 - val_loss: 2.8692\n",
      "Epoch 821/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7967 - val_loss: 2.8710\n",
      "Epoch 822/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8029 - val_loss: 2.8621\n",
      "Epoch 823/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8011 - val_loss: 2.8533\n",
      "Epoch 824/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8108 - val_loss: 2.8480\n",
      "Epoch 825/2500\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.7996 - val_loss: 2.8473\n",
      "Epoch 826/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8015 - val_loss: 2.8490\n",
      "Epoch 827/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7987 - val_loss: 2.8538\n",
      "Epoch 828/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8016 - val_loss: 2.8600\n",
      "Epoch 829/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8032 - val_loss: 2.8657\n",
      "Epoch 830/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7986 - val_loss: 2.8669\n",
      "Epoch 831/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8000 - val_loss: 2.8677\n",
      "Epoch 832/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7927 - val_loss: 2.8669\n",
      "Epoch 833/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7932 - val_loss: 2.8670\n",
      "Epoch 834/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8031 - val_loss: 2.8729\n",
      "Epoch 835/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.7899 - val_loss: 2.8824\n",
      "Epoch 836/2500\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.8019 - val_loss: 2.8827\n",
      "Epoch 837/2500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 2.7997 - val_loss: 2.8804\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=64,\n",
    "    epochs=2500,\n",
    "    callbacks=[early_stopping], # put your callbacks in a list\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21cb1f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the learning curves\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64c649e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum validation loss: 2.823979616165161\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0833227a-788c-452b-a0e3-30515ae2f1a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
